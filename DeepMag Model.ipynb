{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e456354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from scipy import integrate\n",
    "from scipy import signal\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Reshape, Flatten, concatenate, Dot, Concatenate, Lambda\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(\"husl\")\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras.layers import Input, LSTM, Flatten, Dense, Conv1D, Dropout, MaxPooling1D\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2150186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_df(df):\n",
    "    mag=df['Magnitude']\n",
    "    selected_features=[\"RSSC Vel\",\n",
    "                   \"CAV\",\"TP\",\n",
    "                   \"Tau c\",\"Max Acc Index UD\",\"IV_2\",\n",
    "                           \"Cheby Tau c\",\"Arias intensity UD\",\n",
    "                   \"Cheby IV_2\",\"CAD\",\"Cheby RSSC Vel\"]\n",
    "    df=df[selected_features]\n",
    "    return df,mag\n",
    "def create_image_dataset():\n",
    "    df=pd.read_csv(\"E:/ICRAGEE 2024/Result India/Test_tab_MAG_data_3C.csv\",sep=',')\n",
    "    tab_test,y_test=select_df(df)\n",
    "    df=pd.read_csv(\"E:/ICRAGEE 2024/Result India/Val_tab_MAG_data_3C.csv\",sep=',')\n",
    "    tab_val,y_val=select_df(df)\n",
    "    df=pd.read_csv(\"E:/ICRAGEE 2024/Result India/Train_tab_MAG_data_3C.csv\",sep=',')\n",
    "    tab_train,y_train=select_df(df)\n",
    "    seismic_test = np.load('E:/ICRAGEE 2024/Result India/Test_waveform_MAG_data_3C.npy')\n",
    "    seismic_train = np.load('E:/ICRAGEE 2024/Result India/Train_waveform_MAG_data_3C.npy')\n",
    "    seismic_val = np.load('E:/ICRAGEE 2024/Result India/Val_waveform_MAG_data_3C.npy')\n",
    "    return y_train,y_test,y_val, seismic_train, seismic_test, seismic_val,tab_train,tab_test, tab_val\n",
    "\n",
    "# Create the image dataset\n",
    "y_train,y_test,y_val, seismic_train, seismic_test, seismic_val,tab_train,tab_test, tab_val=create_image_dataset()\n",
    "print(\"X train size:\",y_train.shape)\n",
    "print(\"X test size:\", y_test.shape)\n",
    "print(\"X validation size:\",y_val.shape)\n",
    "print(\"X waveform validation size:\",seismic_val.shape)\n",
    "def change_to_tensor(arr):\n",
    "    x_tensor = tf.convert_to_tensor(arr.astype(np.float32))\n",
    "    return x_tensor\n",
    "y_train=change_to_tensor(y_train)\n",
    "y_test=change_to_tensor(y_test)\n",
    "y_val=change_to_tensor(y_val)\n",
    "tab_test=change_to_tensor(np.array(tab_test))\n",
    "tab_train=change_to_tensor(np.array(tab_train))\n",
    "tab_val=change_to_tensor(np.array(tab_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360da02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model on GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    def train_evaluate(ga_individual_solution):  \n",
    "        num_units_bits_LSTM1 = BitArray(ga_individual_solution[0:6]) \n",
    "        num_units_bits_LSTM2 = BitArray(ga_individual_solution[6:]) \n",
    "        num_units_bits_LSTM1 = num_units_bits_LSTM1.uint\n",
    "        num_units_bits_LSTM2 = num_units_bits_LSTM2.uint\n",
    "        print('\\nNum of Units LSTM 1: ', num_units_bits_LSTM1, ', Num of Units LSTM 2: ', num_units_bits_LSTM2)\n",
    "        if num_units_bits_LSTM1 == 0 or num_units_bits_LSTM2 == 0:\n",
    "            return 32, \n",
    "        your_target_height = 128\n",
    "        your_target_width = 128\n",
    "        your_sequence_length = 300 \n",
    "        your_num_features = 3\n",
    "        lstm_input = Input(shape=(your_sequence_length, your_num_features)) \n",
    "        lstm_layer_1 = LSTM(num_units_bits_LSTM1,return_sequences=True)(lstm_input)\n",
    "        lstm_layer_2 = LSTM(num_units_bits_LSTM2)(lstm_layer_1)\n",
    "        flatten_layer = Flatten()(lstm_layer_2)\n",
    "        dense1 = Dense(64, activation='relu')(flatten_layer)\n",
    "        predicted_values = Dense(1, activation='linear')(dense1)\n",
    "        model = Model(inputs=[lstm_input], outputs=predicted_values)\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=0.0001,\n",
    "                decay_steps=10,\n",
    "                decay_rate=0.96\n",
    "            )\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "        model.compile(optimizer=optimizer,loss='mean_squared_error')\n",
    "        model.fit(x=seismic_train, y=y_train, batch_size=32, epochs=100, \n",
    "              validation_data=(seismic_val, y_val))\n",
    "        y_pred = model.predict(seismic_test)   \n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        print('Validation RMSE: ', rmse,'\\n')\n",
    "        return rmse,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf77ab-7561-4978-b0a0-17c0f497856d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "population_size = 4\n",
    "num_generations = 4\n",
    "gene_length = 10\n",
    "creator.create('FitnessMax', base.Fitness, weights = (-1.0,))\n",
    "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "toolbox.register('mate', tools.cxOrdered)\n",
    "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
    "toolbox.register('select', tools.selRoulette)\n",
    "toolbox.register('evaluate', train_evaluate)\n",
    "population = toolbox.population(n = population_size)\n",
    "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, ngen = num_generations, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e919652-1629-40d8-b91b-bf689c63d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_individuals_data = tools.selBest(population,k = 1) #select top 1 solution\n",
    "optimal_window_size = None\n",
    "optimal_num_units = None\n",
    "\n",
    "for bi in optimal_individuals_data:\n",
    "    window_size_bits = BitArray(bi[0:6])\n",
    "    num_units_bits = BitArray(bi[6:]) \n",
    "    num_units_bits_LSTM1 = window_size_bits.uint\n",
    "    num_units_bits_LSTM2 = num_units_bits.uint\n",
    "    print('\\n Best Num of Units LSTM 1: ', num_units_bits_LSTM1, ', Best Num of Units LSTM 2: ', num_units_bits_LSTM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d0095-51d6-42fa-b8c9-5316faa3ff22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    def create_attention_lstm(target_height, target_width, your_sequence_length, your_num_features,num_units_bits_LSTM1,num_units_bits_LSTM2):\n",
    "        lstm_input = Input(shape=(your_sequence_length, your_num_features)) \n",
    "        lstm_layer_1 = LSTM(num_units_bits_LSTM1,return_sequences=True)(lstm_input)\n",
    "        lstm_layer_2 = LSTM(num_units_bits_LSTM2)(lstm_layer_1)\n",
    "        flatten_layer = Flatten()(lstm_layer_2)\n",
    "        dense1 = Dense(12, activation='relu')(flatten_layer)\n",
    "        output_layer = Dense(1, activation='linear')(dense1)\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=0.0001,\n",
    "                decay_steps=10,\n",
    "                decay_rate=0.96\n",
    "            )\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "        model_cnn_bilstm = Model(inputs=[lstm_input], outputs=output_layer)\n",
    "        model_cnn_bilstm.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "        return model_cnn_bilstm\n",
    "\n",
    "    your_target_height = 128\n",
    "    your_target_width = 128\n",
    "    your_sequence_length = 300 \n",
    "    your_num_features = 3\n",
    "    model = create_attention_lstm(your_target_height, your_target_width, your_sequence_length, your_num_features,num_units_bits_LSTM1,num_units_bits_LSTM2)\n",
    "    checkpoint = ModelCheckpoint(filepath='Attention_weights.hdf5', save_best_only=True, monitor='val_mae', mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(x=seismic_train, y=y_train, batch_size=32, epochs=100, \n",
    "              validation_data=(seismic_val, y_val),callbacks=[early_stopping,checkpoint])\n",
    "    model.load_weights('Attention_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model_Magnitude.h5')\n",
    "y_pred = model.predict([seismic_test])\n",
    "y_pred_train = model.predict([seismic_train])\n",
    "xgb_model = xgb.XGBRegressor(max_depth=3,learning_rate=0.1,n_estimators=230,subsample=0.7,seed=1,\n",
    "                            alpha=0.1,min_child_weight=1,random_state=1,scale_pos_weight = 1,base_score=300,\n",
    "                            reg_lambda=0.2 )\n",
    "combined_data = np.concatenate((tab_train,y_pred_train), axis=1)\n",
    "xgb_model.fit(combined_data, y_train)\n",
    "combined_data = np.concatenate((tab_test, y_pred ), axis=1)\n",
    "y_pred_test=xgb_model.predict(combined_data)\n",
    "\n",
    "mae = mean_absolute_error(y_test,y_pred_test)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "plt.scatter(y_test,y_pred_test,s=10,color='black')\n",
    "plt.xlim(2, 8)\n",
    "plt.ylim(2, 8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8ce16-0253-4922-a4db-d34fe52604db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff518b-dc3a-48f3-82c8-ee72ea9a6c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
